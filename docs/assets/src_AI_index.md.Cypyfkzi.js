import{_ as t,c as l,o as i,U as s,m as a,a as e}from"./chunks/framework.D5qs8jox.js";const f=JSON.parse('{"title":"AI 与 AI 安全的一些基本概念","description":"","frontmatter":{},"headers":[],"relativePath":"src/AI/index.md","filePath":"src/AI/index.md","lastUpdated":1708313060000}'),n={name:"src/AI/index.md"},r=s('<h1 id="ai-与-ai-安全的一些基本概念" tabindex="-1">AI 与 AI 安全的一些基本概念 <a class="header-anchor" href="#ai-与-ai-安全的一些基本概念" aria-label="Permalink to &quot;AI 与 AI 安全的一些基本概念&quot;">​</a></h1><h2 id="_1-机器学习-深度学习-强化学习的基本概念及关系" tabindex="-1">1. 机器学习/深度学习/强化学习的基本概念及关系： <a class="header-anchor" href="#_1-机器学习-深度学习-强化学习的基本概念及关系" aria-label="Permalink to &quot;1. 机器学习/深度学习/强化学习的基本概念及关系：&quot;">​</a></h2><h4 id="_1-机器学习-通过机器学习过程的具有无确定规则的定义功能的程序" tabindex="-1">(1) 机器学习：通过机器学习过程的具有无确定规则的定义功能的程序 <a class="header-anchor" href="#_1-机器学习-通过机器学习过程的具有无确定规则的定义功能的程序" aria-label="Permalink to &quot;(1) 机器学习：通过机器学习过程的具有无确定规则的定义功能的程序&quot;">​</a></h4><h4 id="_2-神经网络-在机器学习的算法基础上添加模拟人类神经网络的结构" tabindex="-1">(2) 神经网络：在机器学习的算法基础上添加模拟人类神经网络的结构 <a class="header-anchor" href="#_2-神经网络-在机器学习的算法基础上添加模拟人类神经网络的结构" aria-label="Permalink to &quot;(2) 神经网络：在机器学习的算法基础上添加模拟人类神经网络的结构&quot;">​</a></h4><h4 id="_3-强化学习-通过程序与外部环境的反馈做到基于反馈优化计算的功能" tabindex="-1">(3) 强化学习：通过程序与外部环境的反馈做到基于反馈优化计算的功能 <a class="header-anchor" href="#_3-强化学习-通过程序与外部环境的反馈做到基于反馈优化计算的功能" aria-label="Permalink to &quot;(3) 强化学习：通过程序与外部环境的反馈做到基于反馈优化计算的功能&quot;">​</a></h4><h2 id="_2-监督学习与无监督学习的基本概念" tabindex="-1">2. 监督学习与无监督学习的基本概念： <a class="header-anchor" href="#_2-监督学习与无监督学习的基本概念" aria-label="Permalink to &quot;2. 监督学习与无监督学习的基本概念：&quot;">​</a></h2><h4 id="_1-监督学习-数据集有标签-多用于分类、回归问题-如图像识别、垃圾邮件分类等" tabindex="-1">(1) 监督学习：数据集有标签，多用于分类、回归问题，如图像识别、垃圾邮件分类等 <a class="header-anchor" href="#_1-监督学习-数据集有标签-多用于分类、回归问题-如图像识别、垃圾邮件分类等" aria-label="Permalink to &quot;(1) 监督学习：数据集有标签，多用于分类、回归问题，如图像识别、垃圾邮件分类等&quot;">​</a></h4><h4 id="_2-无监督学习-数据集不带标签-多用于聚类、数据降维等-如预训练、入侵检测等" tabindex="-1">(2) 无监督学习：数据集不带标签，多用于聚类、数据降维等，如预训练、入侵检测等 <a class="header-anchor" href="#_2-无监督学习-数据集不带标签-多用于聚类、数据降维等-如预训练、入侵检测等" aria-label="Permalink to &quot;(2) 无监督学习：数据集不带标签，多用于聚类、数据降维等，如预训练、入侵检测等&quot;">​</a></h4><h2 id="_3-敌手模型" tabindex="-1">3. 敌手模型： <a class="header-anchor" href="#_3-敌手模型" aria-label="Permalink to &quot;3. 敌手模型：&quot;">​</a></h2><p><strong>攻击者称为敌手，敌手模型可以从敌手目标、敌手知识、敌手能力、敌手策略 4 个维度刻画</strong></p><h4 id="_1-敌手目标-分为破坏机器学习的机密性、完整性、可用性" tabindex="-1">(1) 敌手目标：分为破坏机器学习的机密性、完整性、可用性 <a class="header-anchor" href="#_1-敌手目标-分为破坏机器学习的机密性、完整性、可用性" aria-label="Permalink to &quot;(1) 敌手目标：分为破坏机器学习的机密性、完整性、可用性&quot;">​</a></h4><ul><li><p>机密性：包含用户隐私的敏感信息不被泄露</p></li><li><p>完整性：敌手诱导模型行为或者使模型在预测中输出指定分类标签</p></li><li><p>可用性：阻止用户获得模型正确的输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖</p></li></ul><h4 id="_2-敌手知识-包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等" tabindex="-1">(2) 敌手知识：包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等 <a class="header-anchor" href="#_2-敌手知识-包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等" aria-label="Permalink to &quot;(2) 敌手知识：包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等&quot;">​</a></h4><h4 id="_3-敌手能力-指敌手在具有一定知识背景下-对模型或者训练数据、测试数据的控制能力" tabindex="-1">(3) 敌手能力：指敌手在具有一定知识背景下，对模型或者训练数据、测试数据的控制能力 <a class="header-anchor" href="#_3-敌手能力-指敌手在具有一定知识背景下-对模型或者训练数据、测试数据的控制能力" aria-label="Permalink to &quot;(3) 敌手能力：指敌手在具有一定知识背景下，对模型或者训练数据、测试数据的控制能力&quot;">​</a></h4><h4 id="_4-敌手策略-指敌手为达到攻击目标-根据自身的知识和能力-采取的具体攻击方式-如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等" tabindex="-1">(4) 敌手策略：指敌手为达到攻击目标，根据自身的知识和能力，采取的具体攻击方式，如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等 <a class="header-anchor" href="#_4-敌手策略-指敌手为达到攻击目标-根据自身的知识和能力-采取的具体攻击方式-如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等" aria-label="Permalink to &quot;(4) 敌手策略：指敌手为达到攻击目标，根据自身的知识和能力，采取的具体攻击方式，如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等&quot;">​</a></h4><h2 id="_4、机器学习的安全威胁以及安全性防御技术" tabindex="-1">4、机器学习的安全威胁以及安全性防御技术 <a class="header-anchor" href="#_4、机器学习的安全威胁以及安全性防御技术" aria-label="Permalink to &quot;4、机器学习的安全威胁以及安全性防御技术&quot;">​</a></h2><h3 id="训练阶段" tabindex="-1">训练阶段 <a class="header-anchor" href="#训练阶段" aria-label="Permalink to &quot;训练阶段&quot;">​</a></h3>',17),o=a("ul",null,[a("li",null,[e("投毒攻击：敌手对训练数据进行修改、删除或注入精心制作的恶意数据，改变训练数据原有的分布，使学习算法在逻辑上发生改变进而威胁目标模型。当模型预测误差小于"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",null,[a("semantics",null,[a("mrow",null,[a("mi",null,"ϵ")]),a("annotation",{encoding:"application/x-tex"},"\\epsilon")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"strut",style:{height:"0.43056em"}}),a("span",{class:"strut bottom",style:{height:"0.43056em","vertical-align":"0em"}}),a("span",{class:"base textstyle uncramped"},[a("span",{class:"mord mathit"},"ϵ")])])]),e("时，其最大容忍修改训练数据集的概率是 b，b 应满足"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",null,[a("semantics",null,[a("mrow",null,[a("mi",null,"b"),a("mo",null,"≤"),a("mfrac",null,[a("mrow",null,[a("mi",null,"ϵ")]),a("mrow",null,[a("mi",null,"ϵ"),a("mo",null,"+"),a("mn",null,"1")])])]),a("annotation",{encoding:"application/x-tex"},"b\\leq\\frac{\\epsilon}{\\epsilon+1}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"strut",style:{height:"0.695392em"}}),a("span",{class:"strut bottom",style:{height:"1.0987230000000001em","vertical-align":"-0.403331em"}}),a("span",{class:"base textstyle uncramped"},[a("span",{class:"mord mathit"},"b"),a("span",{class:"mrel"},"≤"),a("span",{class:"mord reset-textstyle textstyle uncramped"},[a("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),a("span",{class:"mfrac"},[a("span",{class:"vlist"},[a("span",{style:{top:"0.345em"}},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),a("span",{class:"reset-textstyle scriptstyle cramped"},[a("span",{class:"mord scriptstyle cramped"},[a("span",{class:"mord mathit"},"ϵ"),a("span",{class:"mbin"},"+"),a("span",{class:"mord mathrm"},"1")])])]),a("span",{style:{top:"-0.22999999999999998em"}},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),a("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),a("span",{style:{top:"-0.394em"}},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),a("span",{class:"reset-textstyle scriptstyle uncramped"},[a("span",{class:"mord scriptstyle uncramped"},[a("span",{class:"mord mathit"},"ϵ")])])]),a("span",{class:"baseline-fix"},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),a("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])])],-1),h=s('<h3 id="预测阶段" tabindex="-1">预测阶段 <a class="header-anchor" href="#预测阶段" aria-label="Permalink to &quot;预测阶段&quot;">​</a></h3><ul><li>对抗攻击：敌手精心制造使模型错分类的样本称为对抗样本，此阶段的攻击分为黑盒攻击和白盒攻击</li><li>询问攻击：通过观察特定的输入对应的输出信息，建立与目标模型相似的模型进行攻击</li></ul><h3 id="机器学习的安全性防御技术" tabindex="-1">机器学习的安全性防御技术 <a class="header-anchor" href="#机器学习的安全性防御技术" aria-label="Permalink to &quot;机器学习的安全性防御技术&quot;">​</a></h3><ul><li><p>正则化：通过为代价函数添加正则项（也叫惩罚项）提高目标模型的泛化能力，在预测中遇见未知数据集具有良好的适应性抵抗攻击</p></li><li><p>对抗训练：在训练数据集中引入对抗样本，通过合法化的对抗样本对目标模型的训练提供模型的顽健性 (由于在对抗训练中引入所有未知攻击的对抗样本是不现实的，对抗样本的非适应性导致对抗训练的局限性)</p></li><li><p>防御精馏：防御者与敌手之间的博弈可表示为：敌手最小化制造样本的成本，防御者最小化存在对抗样本的代价函数。防御者与敌手不断交互博弈的过程增加目标模型的顽健性</p></li></ul><h2 id="_5、机器学习的隐私威胁及隐私保护技术" tabindex="-1">5、机器学习的隐私威胁及隐私保护技术 <a class="header-anchor" href="#_5、机器学习的隐私威胁及隐私保护技术" aria-label="Permalink to &quot;5、机器学习的隐私威胁及隐私保护技术&quot;">​</a></h2><h3 id="训练阶段-1" tabindex="-1">训练阶段 <a class="header-anchor" href="#训练阶段-1" aria-label="Permalink to &quot;训练阶段&quot;">​</a></h3><ul><li>窃取训练数据：机器学习训练方式分为集中式和联合分布式</li></ul><h3 id="预测阶段-1" tabindex="-1">预测阶段 <a class="header-anchor" href="#预测阶段-1" aria-label="Permalink to &quot;预测阶段&quot;">​</a></h3><ul><li><p>逆向攻击：可以提取训练数据(部分或全部)或训练数据的统计特征</p></li><li><p>成员推理攻击：给定一条记录可以判定是否在训练数据集中</p></li></ul><h3 id="机器学习隐私保护技术" tabindex="-1">机器学习隐私保护技术 <a class="header-anchor" href="#机器学习隐私保护技术" aria-label="Permalink to &quot;机器学习隐私保护技术&quot;">​</a></h3><ul><li><p>同态加密技术：允许用户直接在密文上做运算，得到的结果解密后与在明文下运算结果一致，是最直接有效保护用户隐私的一项技术</p></li><li><p>差分隐私技术：</p></li></ul>',11),c=[r,o,h];function d(p,u,m,_,b,x){return i(),l("div",null,c)}const k=t(n,[["render",d]]);export{f as __pageData,k as default};
