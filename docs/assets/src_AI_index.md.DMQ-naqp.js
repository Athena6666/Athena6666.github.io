import{_ as s,c as l,o as r,U as t,m as a,a as e}from"./chunks/framework.ByaCay3l.js";const i="/assets/论文1.B64B4ZQt.png",n="/assets/代码.BQidzEaW.png",o="/assets/代码研读.BqYTo1aO.png",h="/assets/代码研读1.C2I0Mwa9.png",c="/assets/文献翻译.BBgWQFUK.png",z=JSON.parse('{"title":"毕设 第一周汇报","description":"","frontmatter":{},"headers":[],"relativePath":"src/AI/index.md","filePath":"src/AI/index.md","lastUpdated":1709089593000}'),p={name:"src/AI/index.md"},d=t('<h1 id="毕设-第一周汇报" tabindex="-1">毕设 第一周汇报 <a class="header-anchor" href="#毕设-第一周汇报" aria-label="Permalink to &quot;毕设 第一周汇报&quot;">​</a></h1><h2 id="一、论文研读" tabindex="-1">一、论文研读 <a class="header-anchor" href="#一、论文研读" aria-label="Permalink to &quot;一、论文研读&quot;">​</a></h2><p><img src="'+i+'" alt="avatar"></p><h2 id="_1-机器学习-深度学习-强化学习的基本概念及关系" tabindex="-1">1. 机器学习/深度学习/强化学习的基本概念及关系： <a class="header-anchor" href="#_1-机器学习-深度学习-强化学习的基本概念及关系" aria-label="Permalink to &quot;1. 机器学习/深度学习/强化学习的基本概念及关系：&quot;">​</a></h2><h4 id="_1-机器学习-通过机器学习过程的具有无确定规则的定义功能的程序" tabindex="-1">(1) 机器学习：通过机器学习过程的具有无确定规则的定义功能的程序 <a class="header-anchor" href="#_1-机器学习-通过机器学习过程的具有无确定规则的定义功能的程序" aria-label="Permalink to &quot;(1) 机器学习：通过机器学习过程的具有无确定规则的定义功能的程序&quot;">​</a></h4><h4 id="_2-神经网络-在机器学习的算法基础上添加模拟人类神经网络的结构" tabindex="-1">(2) 神经网络：在机器学习的算法基础上添加模拟人类神经网络的结构 <a class="header-anchor" href="#_2-神经网络-在机器学习的算法基础上添加模拟人类神经网络的结构" aria-label="Permalink to &quot;(2) 神经网络：在机器学习的算法基础上添加模拟人类神经网络的结构&quot;">​</a></h4><h4 id="_3-强化学习-通过程序与外部环境的反馈做到基于反馈优化计算的功能" tabindex="-1">(3) 强化学习：通过程序与外部环境的反馈做到基于反馈优化计算的功能 <a class="header-anchor" href="#_3-强化学习-通过程序与外部环境的反馈做到基于反馈优化计算的功能" aria-label="Permalink to &quot;(3) 强化学习：通过程序与外部环境的反馈做到基于反馈优化计算的功能&quot;">​</a></h4><h2 id="_2-监督学习与无监督学习的基本概念" tabindex="-1">2. 监督学习与无监督学习的基本概念： <a class="header-anchor" href="#_2-监督学习与无监督学习的基本概念" aria-label="Permalink to &quot;2. 监督学习与无监督学习的基本概念：&quot;">​</a></h2><h4 id="_1-监督学习-数据集有标签-多用于分类、回归问题-如图像识别、垃圾邮件分类等" tabindex="-1">(1) 监督学习：数据集有标签，多用于分类、回归问题，如图像识别、垃圾邮件分类等 <a class="header-anchor" href="#_1-监督学习-数据集有标签-多用于分类、回归问题-如图像识别、垃圾邮件分类等" aria-label="Permalink to &quot;(1) 监督学习：数据集有标签，多用于分类、回归问题，如图像识别、垃圾邮件分类等&quot;">​</a></h4><h4 id="_2-无监督学习-数据集不带标签-多用于聚类、数据降维等-如预训练、入侵检测等" tabindex="-1">(2) 无监督学习：数据集不带标签，多用于聚类、数据降维等，如预训练、入侵检测等 <a class="header-anchor" href="#_2-无监督学习-数据集不带标签-多用于聚类、数据降维等-如预训练、入侵检测等" aria-label="Permalink to &quot;(2) 无监督学习：数据集不带标签，多用于聚类、数据降维等，如预训练、入侵检测等&quot;">​</a></h4><h2 id="_3-敌手模型" tabindex="-1">3. 敌手模型： <a class="header-anchor" href="#_3-敌手模型" aria-label="Permalink to &quot;3. 敌手模型：&quot;">​</a></h2><p><strong>攻击者称为敌手，敌手模型可以从敌手目标、敌手知识、敌手能力、敌手策略 4 个维度刻画</strong></p><h4 id="_1-敌手目标-分为破坏机器学习的机密性、完整性、可用性" tabindex="-1">(1) 敌手目标：分为破坏机器学习的机密性、完整性、可用性 <a class="header-anchor" href="#_1-敌手目标-分为破坏机器学习的机密性、完整性、可用性" aria-label="Permalink to &quot;(1) 敌手目标：分为破坏机器学习的机密性、完整性、可用性&quot;">​</a></h4><ul><li><p>机密性：包含用户隐私的敏感信息不被泄露</p></li><li><p>完整性：敌手诱导模型行为或者使模型在预测中输出指定分类标签</p></li><li><p>可用性：阻止用户获得模型正确的输出或者阻止获取模型本身的一些特性，使其在目标环境下不可信赖</p></li></ul><h4 id="_2-敌手知识-包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等" tabindex="-1">(2) 敌手知识：包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等 <a class="header-anchor" href="#_2-敌手知识-包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等" aria-label="Permalink to &quot;(2) 敌手知识：包括模型的训练数据及特征、模型结构及参数、决策函数、访问目标模型得到反馈信息等&quot;">​</a></h4><h4 id="_3-敌手能力-指敌手在具有一定知识背景下-对模型或者训练数据、测试数据的控制能力" tabindex="-1">(3) 敌手能力：指敌手在具有一定知识背景下，对模型或者训练数据、测试数据的控制能力 <a class="header-anchor" href="#_3-敌手能力-指敌手在具有一定知识背景下-对模型或者训练数据、测试数据的控制能力" aria-label="Permalink to &quot;(3) 敌手能力：指敌手在具有一定知识背景下，对模型或者训练数据、测试数据的控制能力&quot;">​</a></h4><h4 id="_4-敌手策略-指敌手为达到攻击目标-根据自身的知识和能力-采取的具体攻击方式-如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等" tabindex="-1">(4) 敌手策略：指敌手为达到攻击目标，根据自身的知识和能力，采取的具体攻击方式，如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等 <a class="header-anchor" href="#_4-敌手策略-指敌手为达到攻击目标-根据自身的知识和能力-采取的具体攻击方式-如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等" aria-label="Permalink to &quot;(4) 敌手策略：指敌手为达到攻击目标，根据自身的知识和能力，采取的具体攻击方式，如修改数据集标签信息、注入恶意数据、逆向攻击提取敏感数据等&quot;">​</a></h4><h2 id="_4、机器学习的安全威胁以及安全性防御技术" tabindex="-1">4、机器学习的安全威胁以及安全性防御技术 <a class="header-anchor" href="#_4、机器学习的安全威胁以及安全性防御技术" aria-label="Permalink to &quot;4、机器学习的安全威胁以及安全性防御技术&quot;">​</a></h2><h3 id="训练阶段" tabindex="-1">训练阶段 <a class="header-anchor" href="#训练阶段" aria-label="Permalink to &quot;训练阶段&quot;">​</a></h3>',19),m=a("ul",null,[a("li",null,[e("投毒攻击：敌手对训练数据进行修改、删除或注入精心制作的恶意数据，改变训练数据原有的分布，使学习算法在逻辑上发生改变进而威胁目标模型。当模型预测误差小于"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",null,[a("semantics",null,[a("mrow",null,[a("mi",null,"ϵ")]),a("annotation",{encoding:"application/x-tex"},"\\epsilon")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"strut",style:{height:"0.43056em"}}),a("span",{class:"strut bottom",style:{height:"0.43056em","vertical-align":"0em"}}),a("span",{class:"base textstyle uncramped"},[a("span",{class:"mord mathit"},"ϵ")])])]),e("时，其最大容忍修改训练数据集的概率是 b，b 应满足"),a("span",{class:"katex"},[a("span",{class:"katex-mathml"},[a("math",null,[a("semantics",null,[a("mrow",null,[a("mi",null,"b"),a("mo",null,"≤"),a("mfrac",null,[a("mrow",null,[a("mi",null,"ϵ")]),a("mrow",null,[a("mi",null,"ϵ"),a("mo",null,"+"),a("mn",null,"1")])])]),a("annotation",{encoding:"application/x-tex"},"b\\leq\\frac{\\epsilon}{\\epsilon+1}")])])]),a("span",{class:"katex-html","aria-hidden":"true"},[a("span",{class:"strut",style:{height:"0.695392em"}}),a("span",{class:"strut bottom",style:{height:"1.0987230000000001em","vertical-align":"-0.403331em"}}),a("span",{class:"base textstyle uncramped"},[a("span",{class:"mord mathit"},"b"),a("span",{class:"mrel"},"≤"),a("span",{class:"mord reset-textstyle textstyle uncramped"},[a("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"}),a("span",{class:"mfrac"},[a("span",{class:"vlist"},[a("span",{style:{top:"0.345em"}},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),a("span",{class:"reset-textstyle scriptstyle cramped"},[a("span",{class:"mord scriptstyle cramped"},[a("span",{class:"mord mathit"},"ϵ"),a("span",{class:"mbin"},"+"),a("span",{class:"mord mathrm"},"1")])])]),a("span",{style:{top:"-0.22999999999999998em"}},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),a("span",{class:"reset-textstyle textstyle uncramped frac-line"})]),a("span",{style:{top:"-0.394em"}},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),a("span",{class:"reset-textstyle scriptstyle uncramped"},[a("span",{class:"mord scriptstyle uncramped"},[a("span",{class:"mord mathit"},"ϵ")])])]),a("span",{class:"baseline-fix"},[a("span",{class:"fontsize-ensurer reset-size5 size5"},[a("span",{style:{"font-size":"0em"}},"​")]),e("​")])])]),a("span",{class:"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"})])])])])])],-1),u=t('<h3 id="预测阶段" tabindex="-1">预测阶段 <a class="header-anchor" href="#预测阶段" aria-label="Permalink to &quot;预测阶段&quot;">​</a></h3><ul><li>对抗攻击：敌手精心制造使模型错分类的样本称为对抗样本，此阶段的攻击分为黑盒攻击和白盒攻击</li><li>询问攻击：通过观察特定的输入对应的输出信息，建立与目标模型相似的模型进行攻击</li></ul><h3 id="机器学习的安全性防御技术" tabindex="-1">机器学习的安全性防御技术 <a class="header-anchor" href="#机器学习的安全性防御技术" aria-label="Permalink to &quot;机器学习的安全性防御技术&quot;">​</a></h3><ul><li><p>正则化：通过为代价函数添加正则项（也叫惩罚项）提高目标模型的泛化能力，在预测中遇见未知数据集具有良好的适应性抵抗攻击</p></li><li><p>对抗训练：在训练数据集中引入对抗样本，通过合法化的对抗样本对目标模型的训练提供模型的顽健性 (由于在对抗训练中引入所有未知攻击的对抗样本是不现实的，对抗样本的非适应性导致对抗训练的局限性)</p></li><li><p>防御精馏：防御者与敌手之间的博弈可表示为：敌手最小化制造样本的成本，防御者最小化存在对抗样本的代价函数。防御者与敌手不断交互博弈的过程增加目标模型的顽健性</p></li></ul><h2 id="_5、机器学习的隐私威胁及隐私保护技术" tabindex="-1">5、机器学习的隐私威胁及隐私保护技术 <a class="header-anchor" href="#_5、机器学习的隐私威胁及隐私保护技术" aria-label="Permalink to &quot;5、机器学习的隐私威胁及隐私保护技术&quot;">​</a></h2><h3 id="训练阶段-1" tabindex="-1">训练阶段 <a class="header-anchor" href="#训练阶段-1" aria-label="Permalink to &quot;训练阶段&quot;">​</a></h3><ul><li>窃取训练数据：机器学习训练方式分为集中式和联合分布式</li></ul><h3 id="预测阶段-1" tabindex="-1">预测阶段 <a class="header-anchor" href="#预测阶段-1" aria-label="Permalink to &quot;预测阶段&quot;">​</a></h3><ul><li><p>逆向攻击：可以提取训练数据(部分或全部)或训练数据的统计特征</p></li><li><p>成员推理攻击：给定一条记录可以判定是否在训练数据集中</p></li></ul><h3 id="机器学习隐私保护技术" tabindex="-1">机器学习隐私保护技术 <a class="header-anchor" href="#机器学习隐私保护技术" aria-label="Permalink to &quot;机器学习隐私保护技术&quot;">​</a></h3><ul><li><p>同态加密技术：允许用户直接在密文上做运算，得到的结果解密后与在明文下运算结果一致，是最直接有效保护用户隐私的一项技术</p></li><li><p>差分隐私技术：通过引入噪声使至多相差 1 个数据的 2 个数据集查询结果概率不可分</p></li><li><p>安全多方计算(MPC)</p></li></ul><h2 id="二、代码部分" tabindex="-1">二、代码部分 <a class="header-anchor" href="#二、代码部分" aria-label="Permalink to &quot;二、代码部分&quot;">​</a></h2><p>下载了CIFAR-10 数据集，并对数据集进行预处理，进行模型训练，成功跑通，并生成了训练和数据时每个图像类型的准确度和损失函数，用plot绘制出图像，结果如下图所示：</p><p><img src="'+n+'" alt="avatar"></p><p>但是还有两部分没跑通</p><h2 id="三、代码研读" tabindex="-1">三、代码研读 <a class="header-anchor" href="#三、代码研读" aria-label="Permalink to &quot;三、代码研读&quot;">​</a></h2><p>对部分代码进行了研读，发现该项目一共由三部分组成，三种数据集分别是交通工具类，服装类，手写数字图片，然后分别对每个数据集进行训练和测试，对一些函数和专业术语的整理如下：</p><p><img src="'+o+'" alt="avatar"></p><p><strong>(1) learning rate 学习率：学习率决定了每次更新参数时的步长大小。它控制着参数的更新速度。较大的学习率可能导致参数在更新过程中跳过最优解，而较小的学习率可能导致收敛速度过慢。</strong></p><p><strong>(2) torchvision.transforms.ToTensor()：将PIL图像或NumPy数组转换为PyTorch Tensor格式。</strong></p><p><strong>(3) torchvision.transforms.Normalize((0.1307,), (0.3081,))：对输入的张量进行归一化操作。这里的参数表示数据集的均值和标准差，用于将输入数据的每个通道进行归一化，使其均值为 0、标准差为 1。这种归一化通常有助于提高模型的鲁棒性和收敛速度。</strong></p><p><strong>(4) trainset=torchvision.datasets.FashionMNIST(&#39;../../Datasets/&#39;,train=True,transform=train_transform, download=True)：</strong><strong>通过 torchvision.datasets.FashionMNIST 创建了一个 FashionMNIST 数据集的实例FashionMNIST 是一个包含服装类别的图像数据集，用于图像分类任务。其中参数如下：</strong></p><ul><li>train=True：表示创建的是训练集。如果设置为 False，则创建测试集。</li><li>transform=train_transform：指定了之前定义的数据预处理转换操作集合 train_transform，用于对图像进行预处理。</li><li>download=True：如果数据集尚未下载到指定路径（&#39;../../Datasets/&#39;），则自动下载。</li></ul><p><strong>(5) trainloader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=2)：</strong><strong>通过 torch.utils.data.DataLoader 创建了一个训练数据加载器 trainloader。数据加载器可以将数据集分批次地提供给模型进行训练，以利用批处理的并行计算能力。其中参数如下：</strong></p><ul><li>trainset：指定要加载的数据集对象</li><li>batch_size：指定每个批次的样本数量</li><li>shuffle=True：表示在每个epoch（训练循环）开始时打乱数据集的顺序，以增加样本间的随机性</li><li>num_workers=2：指定用于数据加载的工作线程数 但是trainloader好像没用到，还有待研究</li></ul><p><strong>(6) shadow_train_sampler = SubsetRandomSampler(shadow_train_idx)：创建一个能够从给定索引列表中随机选择样本的采样器</strong></p><p><strong>(7)<img src="'+h+'" alt="avatar"></strong></p><ul><li>首先，代码通过target_net_type()创建了一个目标模型target_net，并将其移到到指定设备上</li><li>然后，通过target_net.apply(models.weights_init)应用了一个初始化函数models.weights_init，用于初始化目标模型的权重</li><li>接着，用nn.CrossEntropyLoss()定义了目标模型的损失函数target_loss，用于计算模型在训练中的损失</li><li>最后，使用optim.Adam(target_net.parameters(), lr=lr) 创建了一个Adam优化器 target_optim，用于更新目标模型的参数。</li></ul><p><strong>(8) def train(net, data_loader, test_loader, optimizer, criterion, n_epochs, classes=None, verbose=False)，训练函数中的各参数解释如下：</strong></p><ul><li>optimizer：优化器</li><li>criterion：常用的损失函数</li><li>n_epochs：整数类型的可选项，默认为4。表示训练模型的周期数，一个周期是指对训练数据集进行完整的一次循环</li><li>verbose：日志显示</li></ul><h2 id="四、论文翻译" tabindex="-1">四、论文翻译 <a class="header-anchor" href="#四、论文翻译" aria-label="Permalink to &quot;四、论文翻译&quot;">​</a></h2><p>将之前选的英文文献翻译了一下 <img src="'+c+'" alt="avatar"></p>',32),_=[d,m,u];function b(f,x,g,q,k,P){return r(),l("div",null,_)}const T=s(p,[["render",b]]);export{z as __pageData,T as default};
